# Лабораторная работа 2. Классификация текстов на основе вхождения в документ словарных слов

## Описание работы

Этот отчет представляет собой решение лабораторной работы №2 по классификации текстов на основе вхождения в документ словарных слов. Работа выполнена на языке Python с использованием библиотек pandas, numpy, nltk, scikit-learn, matplotlib и seaborn.

## Задания и их реализация

### Задание 1. Загрузка и анализ данных

В этом задании выполняется загрузка новостного датасета `lenta_ru_news_filtered.csv` и анализ его содержимого:

- Подсчет общего количества новостных текстов
- Определение тем новостей
- Подсчет количества новостных текстов в каждой теме
- Визуализация распределения тем

### Задание 2. Предобработка текстов

Выполняется предобработка новостных текстов:

- Приведение к нижнему регистру
- Удаление знаков пунктуации

### Задание 3. Разделение на обучающую и тестовую выборки

Датасет разделяется на обучающую и тестовую части в соотношении 80% к 20%. Выполняется визуализация распределения тем в каждой из частей.

### Задание 4. Подсчет частот слов и создание словарей

Подсчитываются частоты встречаемости слов в предобработанных текстах обучающей части:

- Определяются самые частые слова в целом по всем текстам
- Определяются самые частые слова по каждой теме
- Создаются словари слов, уникальных для каждой темы
- Выполняется визуализация топ-50 уникальных слов для каждой темы

### Задание 5. Классификация текстов

Выполняется классификация новостных текстов из тестовой части датасета на основе top-k слов из словарей, построенных в задании 4:

- Реализуется алгоритм классификации, который для каждого документа считает количество слов из словаря каждой темы и выбирает тему с максимальным количеством совпадений
- Обрабатываются случаи, когда количество слов одинаковое или равно 0
- Оцениваются показатели точности и полноты классификации при различных значениях k

### Задание 6. Изучение библиотеки Natasha

В этом задании выполняется ознакомление с библиотекой Natasha для обработки текстов на русском языке:

- Рассматриваются возможности библиотеки для сегментации на предложения, морфологического и синтаксического анализа
- Приводятся примеры использования компонентов библиотеки

### Задание 7. Добавление столбца с лемматизированными текстами

Добавляется столбец в обучающую и тестовую части датасета с обработанными текстами после лемматизации:

- Реализуется лемматизация с помощью библиотеки Natasha (если доступна)
- В качестве альтернативы используется простая лемматизация через стеммер Snowball

### Задание 8. Словари на основе лемматизированных текстов

Составляются словари на основе текстов обучающей части датасета по аналогии с заданием 4, но с текстами, полученными после лемматизации:

- Подсчитываются частоты слов в лемматизированных текстах
- Создаются словари уникальных слов для каждой темы

### Задание 9. Классификация на основе лемматизированных текстов

Выполняется классификация новостных текстов тестовой части датасета по аналогии с заданием 5, но с текстами, полученными после лемматизации:

- Реализуется алгоритм классификации на основе лемматизированных текстов
- Оцениваются показатели точности и полноты классификации при различных значениях k

## Файлы с результатами

В результате выполнения лабораторной работы были созданы следующие файлы:

1. `lab2_solution.py` - основной скрипт с реализацией всех заданий
2. `train_results.csv` - обучающая выборка с добавленными столбцами
3. `test_results.csv` - тестовая выборка с результатами классификации
4. `topic_distribution.png` - диаграмма распределения тем в полном датасете
5. `train_test_topic_distribution.png` - диаграммы распределения тем в обучающей и тестовой выборках
6. `unique_words_by_topic.png` - диаграммы топ-50 уникальных слов для каждой темы

## Выводы

В ходе выполнения лабораторной работы была реализована система классификации текстов на основе частотного анализа слов. Были рассмотрены два подхода: на основе исходных текстов и на основе лемматизированных текстов. Проведена оценка качества классификации при различных параметрах.
