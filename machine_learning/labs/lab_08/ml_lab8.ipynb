{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 8. Выбор оптимального классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой лабораторной работе вам потребуется выбрать наилучший классификатор с оптимальными параметрами для задачи про пассажиров [\"Титаника\"](https://ru.wikipedia.org/wiki/Титаник)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1.__  \n",
    "Загрузите данные (см. предыдущую лабораторную работу)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('input/train.csv')\n",
    "test_data = pd.read_csv('input/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2.__  \n",
    "Проведите предобработку данных (см. предыдущую лабораторную работу)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные были предобработаны в лабораторной работе № 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 3.__  \n",
    "Примените масштабирование признаков (`StandardScaler`, `MinMaxScaler`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающие данные после StandardScaler:\n",
      "        Age     SibSp     Parch      Fare\n",
      "0 -0.095928  0.432793 -0.473674 -0.502445\n",
      "1  0.806944  0.432793 -0.473674  0.786845\n",
      "2  0.129790 -0.474545 -0.473674 -0.488854\n",
      "3  0.637655  0.432793 -0.473674  0.420730\n",
      "4  0.637655 -0.474545 -0.473674 -0.486337\n",
      "\n",
      "Статистика после StandardScaler:\n",
      "                Age         SibSp         Parch          Fare\n",
      "count  8.910000e+02  8.910000e+02  8.910000e+02  8.910000e+02\n",
      "mean   3.588600e-17  4.386066e-17  5.382900e-17  3.987333e-18\n",
      "std    1.000562e+00  1.000562e+00  1.000562e+00  1.000562e+00\n",
      "min   -1.365592e+00 -4.745452e-01 -4.736736e-01 -6.484217e-01\n",
      "25%   -9.988002e-01 -4.745452e-01 -4.736736e-01 -4.891482e-01\n",
      "50%    1.693075e-02 -4.745452e-01 -4.736736e-01 -3.573909e-01\n",
      "75%    6.376552e-01  4.327934e-01 -4.736736e-01 -2.424635e-02\n",
      "max    3.176983e+00  6.784163e+00  6.974147e+00  9.667167e+00\n",
      "\n",
      "Обучающие данные после MinMaxScaler:\n",
      "        Age  SibSp  Parch      Fare\n",
      "0  0.279503  0.125    0.0  0.014151\n",
      "1  0.478261  0.125    0.0  0.139136\n",
      "2  0.329193  0.000    0.0  0.015469\n",
      "3  0.440994  0.125    0.0  0.103644\n",
      "4  0.440994  0.000    0.0  0.015713\n",
      "\n",
      "Статистика после MinMaxScaler:\n",
      "              Age       SibSp       Parch        Fare\n",
      "count  891.000000  891.000000  891.000000  891.000000\n",
      "mean     0.300621    0.065376    0.063599    0.062858\n",
      "std      0.220263    0.137843    0.134343    0.096995\n",
      "min      0.000000    0.000000    0.000000    0.000000\n",
      "25%      0.080745    0.000000    0.000000    0.015440\n",
      "50%      0.304348    0.000000    0.000000    0.028213\n",
      "75%      0.440994    0.125000    0.000000    0.060508\n",
      "max      1.000000    1.000000    1.000000    1.000000\n"
     ]
    }
   ],
   "source": [
    "numeric_features = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "\n",
    "# Создание экземпляра StandardScaler\n",
    "scaler_standard = StandardScaler()\n",
    "\n",
    "# Масштабирование числовых признаков в обучающих данных\n",
    "train_data[numeric_features] = scaler_standard.fit_transform(train_data[numeric_features])\n",
    "\n",
    "# Масштабирование числовых признаков в тестовых данных\n",
    "test_data[numeric_features] = scaler_standard.transform(test_data[numeric_features])\n",
    "\n",
    "print(\"Обучающие данные после StandardScaler:\")\n",
    "print(train_data[numeric_features].head())\n",
    "print(\"\\nСтатистика после StandardScaler:\")\n",
    "print(train_data[numeric_features].describe())\n",
    "\n",
    "# Создание экземпляра MinMaxScaler\n",
    "scaler_minmax = MinMaxScaler()\n",
    "\n",
    "# Масштабирование числовых признаков в обучающих данных\n",
    "train_data[numeric_features] = scaler_minmax.fit_transform(train_data[numeric_features])\n",
    "\n",
    "# Масштабирование числовых признаков в тестовых данных\n",
    "test_data[numeric_features] = scaler_minmax.transform(test_data[numeric_features])\n",
    "\n",
    "print(\"\\nОбучающие данные после MinMaxScaler:\")\n",
    "print(train_data[numeric_features].head())\n",
    "print(\"\\nСтатистика после MinMaxScaler:\")\n",
    "print(train_data[numeric_features].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 4.__  \n",
    "Примените различные преобразования признаков (`PolynomialFeatures`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающие данные после преобразования:\n",
      "   Unnamed: 0  PassengerId  Pclass  Pclass_1  Pclass_2  Pclass_3  Sex_female  \\\n",
      "0           0            1       3         0         0         1           0   \n",
      "1           1            2       1         1         0         0           1   \n",
      "2           2            3       3         0         0         1           1   \n",
      "3           3            4       1         1         0         0           1   \n",
      "4           4            5       3         0         0         1           0   \n",
      "\n",
      "   Sex_male  Age_categories_Missing  Age_categories_Infant  ...     Age^2  \\\n",
      "0         1                       0                      0  ...  0.078122   \n",
      "1         0                       0                      0  ...  0.228733   \n",
      "2         0                       0                      0  ...  0.108368   \n",
      "3         0                       0                      0  ...  0.194476   \n",
      "4         1                       0                      0  ...  0.194476   \n",
      "\n",
      "   Age SibSp  Age Parch  Age Fare   SibSp^2  SibSp Parch  SibSp Fare  Parch^2  \\\n",
      "0   0.034938        0.0  0.003955  0.015625          0.0    0.001769      0.0   \n",
      "1   0.059783        0.0  0.066543  0.015625          0.0    0.017392      0.0   \n",
      "2   0.000000        0.0  0.005092  0.000000          0.0    0.000000      0.0   \n",
      "3   0.055124        0.0  0.045706  0.015625          0.0    0.012956      0.0   \n",
      "4   0.000000        0.0  0.006929  0.000000          0.0    0.000000      0.0   \n",
      "\n",
      "   Parch Fare    Fare^2  \n",
      "0         0.0  0.000200  \n",
      "1         0.0  0.019359  \n",
      "2         0.0  0.000239  \n",
      "3         0.0  0.010742  \n",
      "4         0.0  0.000247  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "Форма обучающих данных: (891, 30)\n",
      "\n",
      "Новые признаки:\n",
      "['Age' 'SibSp' 'Parch' 'Fare' 'Age^2' 'Age SibSp' 'Age Parch' 'Age Fare'\n",
      " 'SibSp^2' 'SibSp Parch' 'SibSp Fare' 'Parch^2' 'Parch Fare' 'Fare^2']\n"
     ]
    }
   ],
   "source": [
    "# Создание экземпляра PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# Заполнение пропущенных значений средними значениями\n",
    "numeric_features = ['Age', 'SibSp', 'Parch', 'Fare']\n",
    "train_data[numeric_features] = train_data[numeric_features].fillna(train_data[numeric_features].mean())\n",
    "test_data[numeric_features] = test_data[numeric_features].fillna(test_data[numeric_features].mean())\n",
    "\n",
    "# Преобразование числовых признаков в обучающих данных\n",
    "X_train_poly = poly.fit_transform(train_data[numeric_features])\n",
    "\n",
    "# Преобразование числовых признаков в тестовых данных\n",
    "X_test_poly = poly.transform(test_data[numeric_features])\n",
    "\n",
    "# Получение названий новых признаков\n",
    "new_feature_names = poly.get_feature_names_out(numeric_features)\n",
    "\n",
    "# Создание DataFrame с новыми признаками\n",
    "X_train_poly_df = pd.DataFrame(X_train_poly, columns=new_feature_names)\n",
    "X_test_poly_df = pd.DataFrame(X_test_poly, columns=new_feature_names)\n",
    "\n",
    "# Объединение новых признаков с исходными данными\n",
    "train_data = pd.concat([train_data.drop(numeric_features, axis=1), X_train_poly_df], axis=1)\n",
    "test_data = pd.concat([test_data.drop(numeric_features, axis=1), X_test_poly_df], axis=1)\n",
    "\n",
    "print(\"Обучающие данные после преобразования:\")\n",
    "print(train_data.head())\n",
    "print(\"\\nФорма обучающих данных:\", train_data.shape)\n",
    "print(\"\\nНовые признаки:\")\n",
    "print(new_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 5.__  \n",
    "Обучите несколько классификаторов, в том числе:  \n",
    "1. Логистическую регрессию (`LogisticRegression`).\n",
    "1. Метод опорных векторов (`SVC`).\n",
    "1. Метод *k* ближайших соседей (`KNeighborsClassifier`).\n",
    "1. Наивный байесовский классификатор (`MultinomialNB`).\n",
    "1. Деревья решений (`DecisionTreeClassifier`).\n",
    "1. Случайный лес (`RandomForestClassifier`).\n",
    "1. AdaBoost (`AdaBoost`).\n",
    "1. Градиентный бустинг (`GradientBoostingClassifier`).\n",
    "\n",
    "Для обучения и проверки качества можно использовать функцию `train_test_split()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры выборок:\n",
      "Обучающая: 712 примеров\n",
      "Валидационная: 179 примеров\n",
      "\n",
      "==================================================\n",
      "Обучение Логистическая регрессия...\n",
      "\n",
      "Метрики качества:\n",
      "Точность (Accuracy) на обучении: 1.0000\n",
      "Точность (Accuracy) на валидации: 1.0000\n",
      "\n",
      "Отчет о классификации (валидация):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       110\n",
      "           1       1.00      1.00      1.00        69\n",
      "\n",
      "    accuracy                           1.00       179\n",
      "   macro avg       1.00      1.00      1.00       179\n",
      "weighted avg       1.00      1.00      1.00       179\n",
      "\n",
      "\n",
      "Средние вероятности классов (валидация):\n",
      "Класс 0 (не выжил): 0.6155\n",
      "Класс 1 (выжил): 0.3845\n",
      "\n",
      "==================================================\n",
      "Обучение Метод опорных векторов...\n",
      "\n",
      "Метрики качества:\n",
      "Точность (Accuracy) на обучении: 0.6559\n",
      "Точность (Accuracy) на валидации: 0.6145\n",
      "\n",
      "Отчет о классификации (валидация):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      1.00      0.76       110\n",
      "           1       0.00      0.00      0.00        69\n",
      "\n",
      "    accuracy                           0.61       179\n",
      "   macro avg       0.31      0.50      0.38       179\n",
      "weighted avg       0.38      0.61      0.47       179\n",
      "\n",
      "\n",
      "==================================================\n",
      "Обучение K-ближайших соседей...\n",
      "\n",
      "Метрики качества:\n",
      "Точность (Accuracy) на обучении: 0.7121\n",
      "Точность (Accuracy) на валидации: 0.6089\n",
      "\n",
      "Отчет о классификации (валидация):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.85      0.73       110\n",
      "           1       0.48      0.22      0.30        69\n",
      "\n",
      "    accuracy                           0.61       179\n",
      "   macro avg       0.56      0.54      0.51       179\n",
      "weighted avg       0.58      0.61      0.56       179\n",
      "\n",
      "\n",
      "Средние вероятности классов (валидация):\n",
      "Класс 0 (не выжил): 0.6615\n",
      "Класс 1 (выжил): 0.3385\n",
      "\n",
      "==================================================\n",
      "Обучение Наивный Байес...\n",
      "\n",
      "Метрики качества:\n",
      "Точность (Accuracy) на обучении: 1.0000\n",
      "Точность (Accuracy) на валидации: 1.0000\n",
      "\n",
      "Отчет о классификации (валидация):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       110\n",
      "           1       1.00      1.00      1.00        69\n",
      "\n",
      "    accuracy                           1.00       179\n",
      "   macro avg       1.00      1.00      1.00       179\n",
      "weighted avg       1.00      1.00      1.00       179\n",
      "\n",
      "\n",
      "Средние вероятности классов (валидация):\n",
      "Класс 0 (не выжил): 0.6148\n",
      "Класс 1 (выжил): 0.3852\n",
      "\n",
      "==================================================\n",
      "Обучение Дерево решений...\n",
      "\n",
      "Метрики качества:\n",
      "Точность (Accuracy) на обучении: 1.0000\n",
      "Точность (Accuracy) на валидации: 1.0000\n",
      "\n",
      "Отчет о классификации (валидация):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       110\n",
      "           1       1.00      1.00      1.00        69\n",
      "\n",
      "    accuracy                           1.00       179\n",
      "   macro avg       1.00      1.00      1.00       179\n",
      "weighted avg       1.00      1.00      1.00       179\n",
      "\n",
      "\n",
      "Средние вероятности классов (валидация):\n",
      "Класс 0 (не выжил): 0.6145\n",
      "Класс 1 (выжил): 0.3855\n",
      "\n",
      "Топ-5 важных признаков:\n",
      "       Признак  Важность\n",
      "6   Sex_female       1.0\n",
      "1  PassengerId       0.0\n",
      "2       Pclass       0.0\n",
      "3     Pclass_1       0.0\n",
      "0   Unnamed: 0       0.0\n",
      "\n",
      "==================================================\n",
      "Обучение Случайный лес...\n",
      "\n",
      "Метрики качества:\n",
      "Точность (Accuracy) на обучении: 1.0000\n",
      "Точность (Accuracy) на валидации: 1.0000\n",
      "\n",
      "Отчет о классификации (валидация):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       110\n",
      "           1       1.00      1.00      1.00        69\n",
      "\n",
      "    accuracy                           1.00       179\n",
      "   macro avg       1.00      1.00      1.00       179\n",
      "weighted avg       1.00      1.00      1.00       179\n",
      "\n",
      "\n",
      "Средние вероятности классов (валидация):\n",
      "Класс 0 (не выжил): 0.6170\n",
      "Класс 1 (выжил): 0.3830\n",
      "\n",
      "Топ-5 важных признаков:\n",
      "       Признак  Важность\n",
      "7     Sex_male  0.448084\n",
      "6   Sex_female  0.445697\n",
      "18        Fare  0.018785\n",
      "28      Fare^2  0.013382\n",
      "22    Age Fare  0.009200\n",
      "\n",
      "==================================================\n",
      "Обучение AdaBoost...\n",
      "\n",
      "Метрики качества:\n",
      "Точность (Accuracy) на обучении: 1.0000\n",
      "Точность (Accuracy) на валидации: 1.0000\n",
      "\n",
      "Отчет о классификации (валидация):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       110\n",
      "           1       1.00      1.00      1.00        69\n",
      "\n",
      "    accuracy                           1.00       179\n",
      "   macro avg       1.00      1.00      1.00       179\n",
      "weighted avg       1.00      1.00      1.00       179\n",
      "\n",
      "\n",
      "Средние вероятности классов (валидация):\n",
      "Класс 0 (не выжил): 0.5872\n",
      "Класс 1 (выжил): 0.4128\n",
      "\n",
      "Топ-5 важных признаков:\n",
      "       Признак  Важность\n",
      "6   Sex_female       1.0\n",
      "1  PassengerId       0.0\n",
      "2       Pclass       0.0\n",
      "3     Pclass_1       0.0\n",
      "0   Unnamed: 0       0.0\n",
      "\n",
      "==================================================\n",
      "Обучение Градиентный бустинг...\n",
      "\n",
      "Метрики качества:\n",
      "Точность (Accuracy) на обучении: 1.0000\n",
      "Точность (Accuracy) на валидации: 1.0000\n",
      "\n",
      "Отчет о классификации (валидация):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       110\n",
      "           1       1.00      1.00      1.00        69\n",
      "\n",
      "    accuracy                           1.00       179\n",
      "   macro avg       1.00      1.00      1.00       179\n",
      "weighted avg       1.00      1.00      1.00       179\n",
      "\n",
      "\n",
      "Средние вероятности классов (валидация):\n",
      "Класс 0 (не выжил): 0.6145\n",
      "Класс 1 (выжил): 0.3855\n",
      "\n",
      "Топ-5 важных признаков:\n",
      "       Признак      Важность\n",
      "7     Sex_male  5.201318e-01\n",
      "6   Sex_female  4.798682e-01\n",
      "18        Fare  2.243729e-15\n",
      "22    Age Fare  1.659835e-15\n",
      "0   Unnamed: 0  1.149945e-15\n",
      "\n",
      "Сводная таблица результатов:\n",
      "                         Train Accuracy  Validation Accuracy\n",
      "Логистическая регрессия        1.000000             1.000000\n",
      "Наивный Байес                  1.000000             1.000000\n",
      "Случайный лес                  1.000000             1.000000\n",
      "Дерево решений                 1.000000             1.000000\n",
      "AdaBoost                       1.000000             1.000000\n",
      "Градиентный бустинг            1.000000             1.000000\n",
      "Метод опорных векторов         0.655899             0.614525\n",
      "K-ближайших соседей            0.712079             0.608939\n"
     ]
    }
   ],
   "source": [
    "# Подготовка данных для обучения\n",
    "X = train_data.drop('Survived', axis=1)\n",
    "y = train_data['Survived']\n",
    "\n",
    "\n",
    "# Разделение данных на обучающую (80%) и валидационную (20%) выборки\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Размеры выборок:\")\n",
    "print(f\"Обучающая: {X_train.shape[0]} примеров\")\n",
    "print(f\"Валидационная: {X_val.shape[0]} примеров\")\n",
    "\n",
    "# Создание списка классификаторов\n",
    "classifiers = {\n",
    "    'Логистическая регрессия': LogisticRegression(random_state=42),\n",
    "    'Метод опорных векторов': SVC(random_state=42),\n",
    "    'K-ближайших соседей': KNeighborsClassifier(),\n",
    "    'Наивный Байес': MultinomialNB(),\n",
    "    'Дерево решений': DecisionTreeClassifier(random_state=42),\n",
    "    'Случайный лес': RandomForestClassifier(random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42),\n",
    "    'Градиентный бустинг': GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Обучение и оценка каждого классификатора\n",
    "results = {}\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Обучение {name}...\")\n",
    "    \n",
    "    # Обучение модели\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Предсказание на обучающих данных\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    \n",
    "    # Предсказание на валидационных данных\n",
    "    y_val_pred = clf.predict(X_val)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    print(f\"\\nМетрики качества:\")\n",
    "    print(f\"Точность (Accuracy) на обучении: {train_accuracy:.4f}\")\n",
    "    print(f\"Точность (Accuracy) на валидации: {val_accuracy:.4f}\")\n",
    "    \n",
    "    print(\"\\nОтчет о классификации (валидация):\")\n",
    "    print(classification_report(y_val, y_val_pred))\n",
    "    \n",
    "    # Вывод вероятностей для каждого класса (если поддерживается)\n",
    "    if hasattr(clf, 'predict_proba'):\n",
    "        y_proba = clf.predict_proba(X_val)\n",
    "        print(\"\\nСредние вероятности классов (валидация):\")\n",
    "        print(f\"Класс 0 (не выжил): {y_proba[:, 0].mean():.4f}\")\n",
    "        print(f\"Класс 1 (выжил): {y_proba[:, 1].mean():.4f}\")\n",
    "    \n",
    "    # Для деревьев и лесов выведем важность признаков\n",
    "    if hasattr(clf, 'feature_importances_'):\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'Признак': X.columns,\n",
    "            'Важность': clf.feature_importances_\n",
    "        }).sort_values('Важность', ascending=False)\n",
    "        print(\"\\nТоп-5 важных признаков:\")\n",
    "        print(feature_importance.head())\n",
    "    \n",
    "    # Сохранение результатов для сравнения\n",
    "    results[name] = {\n",
    "        'Train Accuracy': train_accuracy,\n",
    "        'Validation Accuracy': val_accuracy\n",
    "    }\n",
    "\n",
    "# Вывод сводной таблицы результатов\n",
    "print(\"\\nСводная таблица результатов:\")\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "print(results_df.sort_values('Validation Accuracy', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 6.__  \n",
    "При помощи `Pipeline` и `GridSearchCV` выберите оптимальную архитектуру:\n",
    "1. Метод масштабирования.\n",
    "1. Степень полинома в `PolynomialFeatures`.\n",
    "1. Параметры классификаторов (в том числе, параметры регуляризации).\n",
    "\n",
    "Заносите в таблицу Excel результаты тестирования (варианты параметров, оценки качества)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры выборок:\n",
      "Обучающая выборка: (712, 29)\n",
      "Валидационная выборка: (179, 29)\n",
      "\n",
      "==================================================\n",
      "Оптимизация Логистическая регрессия...\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "\n",
      "Лучшие параметры для Логистическая регрессия:\n",
      "clf__C: 0.1\n",
      "clf__penalty: l1\n",
      "clf__solver: liblinear\n",
      "poly__degree: 1\n",
      "scaler: StandardScaler()\n",
      "\n",
      "Лучший результат на обучающей выборке: 1.0000\n",
      "Результат на валидационной выборке: 1.0000\n",
      "\n",
      "==================================================\n",
      "Оптимизация SVM...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "\n",
      "Лучшие параметры для SVM:\n",
      "clf__C: 0.1\n",
      "clf__gamma: scale\n",
      "clf__kernel: rbf\n",
      "poly__degree: 1\n",
      "scaler: MinMaxScaler()\n",
      "\n",
      "Лучший результат на обучающей выборке: 1.0000\n",
      "Результат на валидационной выборке: 1.0000\n",
      "\n",
      "==================================================\n",
      "Оптимизация Случайный лес...\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "\n",
      "Лучшие параметры для Случайный лес:\n",
      "clf__max_depth: None\n",
      "clf__min_samples_leaf: 1\n",
      "clf__min_samples_split: 2\n",
      "clf__n_estimators: 100\n",
      "poly__degree: 1\n",
      "\n",
      "Лучший результат на обучающей выборке: 1.0000\n",
      "Результат на валидационной выборке: 1.0000\n",
      "\n",
      "==================================================\n",
      "Оптимизация Градиентный бустинг...\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "\n",
      "Лучшие параметры для Градиентный бустинг:\n",
      "clf__learning_rate: 0.01\n",
      "clf__max_depth: 3\n",
      "clf__n_estimators: 100\n",
      "clf__subsample: 0.8\n",
      "poly__degree: 1\n",
      "\n",
      "Лучший результат на обучающей выборке: 1.0000\n",
      "Результат на валидационной выборке: 1.0000\n",
      "\n",
      "Сводная таблица результатов:\n",
      "             Классификатор  Точность на обучающей  Точность на валидационной\n",
      "0  Логистическая регрессия                    1.0                        1.0\n",
      "1                      SVM                    1.0                        1.0\n",
      "2            Случайный лес                    1.0                        1.0\n",
      "3      Градиентный бустинг                    1.0                        1.0\n"
     ]
    }
   ],
   "source": [
    "# Подготовка данных\n",
    "X = train_data.drop('Survived', axis=1)\n",
    "y = train_data['Survived']\n",
    "\n",
    "# Разделение на обучающую и валидационную выборки\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Размеры выборок:\")\n",
    "print(f\"Обучающая выборка: {X_train.shape}\")\n",
    "print(f\"Валидационная выборка: {X_val.shape}\")\n",
    "\n",
    "# Определение пайплайнов и их параметров\n",
    "pipelines = {\n",
    "    'Логистическая регрессия': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures()),\n",
    "        ('clf', LogisticRegression())\n",
    "    ]),\n",
    "    'SVM': Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('poly', PolynomialFeatures()),\n",
    "        ('clf', SVC())\n",
    "    ]),\n",
    "    'Случайный лес': Pipeline([\n",
    "        ('poly', PolynomialFeatures()),\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ]),\n",
    "    'Градиентный бустинг': Pipeline([\n",
    "        ('poly', PolynomialFeatures()),\n",
    "        ('clf', GradientBoostingClassifier())\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Параметры для GridSearchCV\n",
    "param_grids = {\n",
    "    'Логистическая регрессия': {\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        'poly__degree': [1, 2, 3],\n",
    "        'clf__C': [0.1, 1, 10],\n",
    "        'clf__penalty': ['l1', 'l2'],\n",
    "        'clf__solver': ['liblinear']\n",
    "    },\n",
    "    'SVM': {\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        'poly__degree': [1, 2],\n",
    "        'clf__C': [0.1, 1, 10],\n",
    "        'clf__kernel': ['rbf', 'linear'],\n",
    "        'clf__gamma': ['scale', 'auto']\n",
    "    },\n",
    "    'Случайный лес': {\n",
    "        'poly__degree': [1, 2],\n",
    "        'clf__n_estimators': [100, 200],\n",
    "        'clf__max_depth': [None, 10, 20],\n",
    "        'clf__min_samples_split': [2, 5],\n",
    "        'clf__min_samples_leaf': [1, 2]\n",
    "    },\n",
    "    'Градиентный бустинг': {\n",
    "        'poly__degree': [1, 2],\n",
    "        'clf__n_estimators': [100, 200],\n",
    "        'clf__learning_rate': [0.01, 0.1],\n",
    "        'clf__max_depth': [3, 5],\n",
    "        'clf__subsample': [0.8, 1.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Обучение и оценка каждого пайплайна\n",
    "results = {}\n",
    "for name, pipeline in pipelines.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Оптимизация {name}...\")\n",
    "    \n",
    "    # Создание GridSearchCV\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grids[name],\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Обучение на обучающей выборке\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Оценка на валидационной выборке\n",
    "    val_score = grid_search.score(X_val, y_val)\n",
    "    \n",
    "    # Вывод результатов\n",
    "    print(f\"\\nЛучшие параметры для {name}:\")\n",
    "    for param, value in grid_search.best_params_.items():\n",
    "        print(f\"{param}: {value}\")\n",
    "    \n",
    "    print(f\"\\nЛучший результат на обучающей выборке: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"Результат на валидационной выборке: {val_score:.4f}\")\n",
    "    \n",
    "    # Сохранение результатов\n",
    "    results[name] = {\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'train_score': grid_search.best_score_,\n",
    "        'val_score': val_score,\n",
    "        'cv_results': pd.DataFrame(grid_search.cv_results_)\n",
    "    }\n",
    "\n",
    "# Создание сводной таблицы результатов\n",
    "summary = pd.DataFrame({\n",
    "    'Классификатор': list(results.keys()),\n",
    "    'Точность на обучающей': [results[name]['train_score'] for name in results.keys()],\n",
    "    'Точность на валидационной': [results[name]['val_score'] for name in results.keys()]\n",
    "}).sort_values('Точность на валидационной', ascending=False)\n",
    "\n",
    "print(\"\\nСводная таблица результатов:\")\n",
    "print(summary)\n",
    "\n",
    "# Сохранение результатов в Excel\n",
    "with pd.ExcelWriter('grid_search_results.xlsx') as writer:\n",
    "    summary.to_excel(writer, sheet_name='Сводная таблица', index=False)\n",
    "    \n",
    "    for name, result in results.items():\n",
    "        result['cv_results'].to_excel(writer, sheet_name=f'{name[:30]}', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 7.__  \n",
    "1. Выберите несколько лучших классификаторов (от 3 до 10).\n",
    "1. Обучите выбранные классификаторы на всех доступных размеченных данных.\n",
    "1. Получите результаты предсказания для тестовых данных.\n",
    "1. Отправьте результаты на сервер [Kaggle](https://ru.wikipedia.org/wiki/Титаник)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Обучение Случайный лес...\n",
      "\n",
      "Метрики качества на обучающих данных:\n",
      "Точность (Accuracy): 1.0000\n",
      "\n",
      "Отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       577\n",
      "           1       1.00      1.00      1.00       314\n",
      "\n",
      "    accuracy                           1.00       891\n",
      "   macro avg       1.00      1.00      1.00       891\n",
      "weighted avg       1.00      1.00      1.00       891\n",
      "\n",
      "\n",
      "Топ-5 важных признаков:\n",
      "       Признак  Важность\n",
      "7     Sex_male  0.453156\n",
      "6   Sex_female  0.438068\n",
      "18        Fare  0.021477\n",
      "28      Fare^2  0.012443\n",
      "21   Age Parch  0.008612\n",
      "\n",
      "==================================================\n",
      "Обучение Градиентный бустинг...\n",
      "\n",
      "Метрики качества на обучающих данных:\n",
      "Точность (Accuracy): 1.0000\n",
      "\n",
      "Отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       577\n",
      "           1       1.00      1.00      1.00       314\n",
      "\n",
      "    accuracy                           1.00       891\n",
      "   macro avg       1.00      1.00      1.00       891\n",
      "weighted avg       1.00      1.00      1.00       891\n",
      "\n",
      "\n",
      "Топ-5 важных признаков:\n",
      "        Признак      Важность\n",
      "6    Sex_female  5.323306e-01\n",
      "7      Sex_male  4.676694e-01\n",
      "0    Unnamed: 0  6.895386e-15\n",
      "22     Age Fare  2.969045e-15\n",
      "1   PassengerId  1.090503e-15\n",
      "\n",
      "==================================================\n",
      "Обучение Логистическая регрессия...\n",
      "\n",
      "Метрики качества на обучающих данных:\n",
      "Точность (Accuracy): 1.0000\n",
      "\n",
      "Отчет о классификации:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       577\n",
      "           1       1.00      1.00      1.00       314\n",
      "\n",
      "    accuracy                           1.00       891\n",
      "   macro avg       1.00      1.00      1.00       891\n",
      "weighted avg       1.00      1.00      1.00       891\n",
      "\n",
      "\n",
      "Результаты сохранены в файл submission.csv\n",
      "\n",
      "Статистика предсказаний:\n",
      "\n",
      "Случайный лес:\n",
      "Выживших: 152\n",
      "Не выживших: 266\n",
      "\n",
      "Градиентный бустинг:\n",
      "Выживших: 152\n",
      "Не выживших: 266\n",
      "\n",
      "Логистическая регрессия:\n",
      "Выживших: 418\n",
      "Не выживших: 0\n",
      "\n",
      "Ансамбль:\n",
      "Выживших: 152\n",
      "Не выживших: 266\n"
     ]
    }
   ],
   "source": [
    "# Выбор лучших классификаторов\n",
    "best_classifiers = {\n",
    "    'Случайный лес': RandomForestClassifier(random_state=42),\n",
    "    'Градиентный бустинг': GradientBoostingClassifier(random_state=42),\n",
    "    'Логистическая регрессия': LogisticRegression(random_state=42)\n",
    "}\n",
    "\n",
    "# Подготовка данных\n",
    "X = train_data.drop('Survived', axis=1)\n",
    "y = train_data['Survived']\n",
    "\n",
    "# Обучение и оценка лучших классификаторов\n",
    "results = {}\n",
    "for name, clf in best_classifiers.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Обучение {name}...\")\n",
    "    \n",
    "    # Обучение модели\n",
    "    clf.fit(X, y)\n",
    "    \n",
    "    # Предсказание на обучающих данных\n",
    "    y_train_pred = clf.predict(X)\n",
    "    train_accuracy = accuracy_score(y, y_train_pred)\n",
    "    \n",
    "    print(f\"\\nМетрики качества на обучающих данных:\")\n",
    "    print(f\"Точность (Accuracy): {train_accuracy:.4f}\")\n",
    "    print(\"\\nОтчет о классификации:\")\n",
    "    print(classification_report(y, y_train_pred))\n",
    "    \n",
    "    # Предсказание на тестовых данных\n",
    "    y_test_pred = clf.predict(test_data)\n",
    "    results[name] = y_test_pred\n",
    "    \n",
    "    # Вывод важности признаков для моделей, которые это поддерживают\n",
    "    if hasattr(clf, 'feature_importances_'):\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'Признак': X.columns,\n",
    "            'Важность': clf.feature_importances_\n",
    "        }).sort_values('Важность', ascending=False)\n",
    "        print(\"\\nТоп-5 важных признаков:\")\n",
    "        print(feature_importance.head())\n",
    "\n",
    "# Создание ансамбля предсказаний (голосование большинством)\n",
    "ensemble_predictions = np.zeros(len(test_data))\n",
    "for name, preds in results.items():\n",
    "    ensemble_predictions += preds\n",
    "ensemble_predictions = (ensemble_predictions >= 2).astype(int)\n",
    "\n",
    "# Создание DataFrame с предсказаниями для отправки на Kaggle\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_data['PassengerId'],\n",
    "    'Survived': ensemble_predictions\n",
    "})\n",
    "\n",
    "# Сохранение результатов\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"\\nРезультаты сохранены в файл submission.csv\")\n",
    "\n",
    "# Вывод статистики предсказаний\n",
    "print(\"\\nСтатистика предсказаний:\")\n",
    "for name, preds in results.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Выживших: {sum(preds)}\")\n",
    "    print(f\"Не выживших: {len(preds) - sum(preds)}\")\n",
    "\n",
    "print(\"\\nАнсамбль:\")\n",
    "print(f\"Выживших: {sum(ensemble_predictions)}\")\n",
    "print(f\"Не выживших: {len(ensemble_predictions) - sum(ensemble_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
